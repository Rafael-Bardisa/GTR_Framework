//example of some shaders compiled
flat basic.vs flat.fs
texture basic.vs texture.fs
multiphong basic.vs multiphong.fs
singlephong basic.vs singlephong.fs
depth quad.vs depth.fs

gbuffers basic.vs gbuffers.fs
deferred quad.vs deferred.fs

\normal

// the code from the slides
mat3 cotangent_frame(vec3 N, vec3 p, vec2 uv)
{
    // get edge vectors of the pixel triangle
    vec3 dp1 = dFdx( p );
    vec3 dp2 = dFdy( p );
    vec2 duv1 = dFdx( uv );
    vec2 duv2 = dFdy( uv );
    
    // solve the linear system
    vec3 dp2perp = cross( dp2, N );
    vec3 dp1perp = cross( N, dp1 );
    vec3 T = dp2perp * duv1.x + dp1perp * duv2.x;
    vec3 B = dp2perp * duv1.y + dp1perp * duv2.y;
 
    // construct a scale-invariant frame
    float invmax = inversesqrt( max( dot(T,T), dot(B,B) ) );
    return mat3( T * invmax, B * invmax, N );
}

// assume N, the interpolated vertex normal and
// WP the world position
//vec3 normal_pixel = texture2D( normalmap, uv ).xyz;
vec3 perturbNormal(vec3 N, vec3 WP, vec2 uv, vec3 normal_pixel)
{
    normal_pixel = normal_pixel * 255./127. - 128./127.;
    mat3 TBN = cotangent_frame(N, WP, uv);
    return normalize(TBN * normal_pixel);
}

\basic.vs


attribute vec3 a_vertex;
attribute vec3 a_normal;
attribute vec2 a_coord;
attribute vec4 a_color;

uniform vec3 u_camera_pos;

uniform mat4 u_model;
uniform mat4 u_viewprojection;

//this will store the color for the pixel shader
varying vec3 v_position;
varying vec3 v_world_position;
varying vec3 v_normal;
varying vec2 v_uv;
varying vec4 v_color;

void main()
{	
	//calcule the normal in camera space (the NormalMatrix is like ViewMatrix but without traslation)
	v_normal = (u_model * vec4( a_normal, 0.0) ).xyz;
	
	//calcule the vertex in object space
	v_position = a_vertex;
	v_world_position = (u_model * vec4( v_position, 1.0) ).xyz;
	
	//store the color in the varying var to use it from the pixel shader
	v_color = a_color;

	//store the texture coordinates
	v_uv = a_coord;

	//calcule the position of the vertex using the matrices
	gl_Position = u_viewprojection * vec4( v_world_position, 1.0 );
}

\flat.fs


uniform vec4 u_color;

void main()
{
	gl_FragColor = u_color;
}

\gbuffers.fs

varying vec3 v_position;
varying vec3 v_world_position;
varying vec3 v_normal;
varying vec2 v_uv;
varying vec4 v_color;

uniform vec3 u_camera_pos;

uniform vec4 u_color;
uniform sampler2D u_color_texture;
uniform sampler2D u_emissive_texture;
uniform sampler2D u_metallic_texture;
uniform sampler2D u_normal_texture;
uniform sampler2D u_occlusion_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

uniform bool u_use_normalmap;
uniform bool u_dither;

#include "normal"

//from https://github.com/hughsk/glsl-dither/blob/master/4x4.glsl
float dither4x4(vec2 position, float brightness)
{
  int x = int(mod(position.x, 4.0));
  int y = int(mod(position.y, 4.0));
  int index = x + y * 4;
  float limit = 0.0;


if (index == 0) limit = 0.0625;
if (index == 1) limit = 0.5625;
if (index == 2) limit = 0.1875;
if (index == 3) limit = 0.6875;
if (index == 4) limit = 0.8125;
if (index == 5) limit = 0.3125;
if (index == 6) limit = 0.9375;
if (index == 7) limit = 0.4375;
if (index == 8) limit = 0.25;
if (index == 9) limit = 0.75;
if (index == 10) limit = 0.125;
if (index == 11) limit = 0.625;
if (index == 12) limit = 1.0;
if (index == 13) limit = 0.5;
if (index == 14) limit = 0.875;
if (index == 15) limit = 0.375;


  return brightness < limit ? 0.0 : 1.0;
}



void main(){

    
    vec4 color = texture2D(u_color_texture, v_uv);
    if (u_dither && (dither4x4(gl_FragCoord.xy, color.a) == 0.0))
        discard;
    
    vec3 N = vec3(0);

    if (u_use_normalmap)
        N = perturbNormal(v_normal, v_world_position, v_uv, texture2D( u_normal_texture, v_uv ).xyz);
    else
        N = normalize( v_normal );
    
    vec3 material_properties = texture2D(u_emissive_texture, v_uv).xyz;

    gl_FragData[0] = color;
    gl_FragData[1] = vec4(N*0.5+vec3(0.5),1.0);
    gl_FragData[2] = vec4(material_properties, 1.0);

}

\deferred.fs

uniform sampler2D u_color_texture;
uniform sampler2D u_normal_texture;
uniform sampler2D u_extra_texture;
uniform sampler2D u_depth_texture;

uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

//pass here all the uniforms required for illumination...
uniform int u_light_type;

uniform vec3 u_ambient_light;

uniform vec3 u_light_position;
uniform vec3 u_light_color;
uniform vec3 u_light_direction;


uniform float u_max_distance;

uniform float u_cone_angle_cos;
uniform float u_cone_exp;

uniform bool u_use_alpha;
uniform bool u_use_normalmap;

uniform bool u_cast_shadows;
uniform sampler2D u_shadow_atlas;

uniform vec4 u_light_shadow_slot;
uniform mat4 u_light_viewprojection;
uniform float u_shadow_bias;

vec2 reproject_uv(vec2 uv, vec4 dimensions){
    return vec2(dimensions.x + (uv.x * dimensions.z), dimensions.y + (uv.y * dimensions.a));
}

float test_shadowmap(vec3 wp){
    //project our 3D position to the shadowmap
    vec4 proj_pos = u_light_viewprojection * vec4(wp,1.0);

    //from homogeneus space to clip space
    vec2 shadow_uv = proj_pos.xy / proj_pos.w;

    //from clip space to uv space
    shadow_uv = shadow_uv * 0.5 + vec2(0.5);

    //reproject because atlas
    shadow_uv = reproject_uv(shadow_uv, u_light_shadow_slot);

    //get point depth [-1 .. +1] in non-linear space
    float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;

    //normalize from [-1..+1] to [0..+1] still non-linear
    real_depth = real_depth * 0.5 + 0.5;

    //read depth from depth buffer in [0..+1] non-linear
    float shadow_depth = texture2D( u_shadow_atlas, shadow_uv).x;

    //compute final shadow factor by comparing
    float shadow_factor = 1.0;

    //we can compare them, even if they are not linear
    if( shadow_depth < real_depth )
    shadow_factor = 0.0;
    return shadow_factor;
}

float spot_factor(vec3 light_direction, vec3 L, float cos_limit, float cone_exp){
    float light_dot = -dot(light_direction, L);
    if (light_dot < cos_limit){
        return 0.0;
        }
    else{
        light_dot = (light_dot - cos_limit)/(1.0-cos_limit);
        return pow(light_dot, cone_exp);
    }
}

void main()
{
//extract uvs from pixel screenpos
    vec2 uv = gl_FragCoord.xy * u_iRes.xy;
    
    vec3 color = texture2D( u_color_texture, uv ).xyz;
    
    //normals must be converted from 0..1 to -1..+1
    vec3 N = texture2D( u_normal_texture, uv ).xyz * 2.0 - 1.0;
    N = normalize(N); //always normalize in case of data loss
    
    //reconstruct world position from depth and inv. viewproj
    float depth = texture2D( u_depth_texture, uv ).x;
    vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
    vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
    vec3 world_position = proj_worldpos.xyz / proj_worldpos.w;
    //now do your illumination using worldpos and the normal...
    vec3 light = u_ambient_light;
    
    float att_factor = 1.0;
    //hol up
    vec3 L = u_light_direction;
    
    if (u_light_type != 3){
    //compute att factor and L if light is not directional
        L = u_light_position - world_position;
        float light_distance = length(L);
        L /= light_distance;
        
        att_factor =  u_max_distance - light_distance;
        att_factor = max(att_factor / u_max_distance, 0.0);
        att_factor = pow(att_factor, 2.0);
    }else{
    L = normalize(L);
    }



    float NdotL = clamp(dot(N, L), 0.0, 1.0);
    float spot_factor = 1.0;
    
    float shadow_factor = 1.0;
    if (u_light_type == 2){
    //spot factor if light is spot
    spot_factor = spot_factor(u_light_direction, L, u_cone_angle_cos, u_cone_exp);
    if(u_cast_shadows){
        shadow_factor = test_shadowmap(world_position);
        }
    }



    //store the amount of diffuse light
    light += u_light_color * NdotL * att_factor * spot_factor * shadow_factor;
    
    gl_FragData[0] = vec4(color, 1.0);
    
}

\texture.fs

varying vec3 v_position;
varying vec3 v_world_position;
varying vec3 v_normal;
varying vec2 v_uv;
varying vec4 v_color;

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture2D( u_texture, uv );

	if(color.a < u_alpha_cutoff)
		discard;

	gl_FragColor = color;
}

\multiphong.fs


varying vec3 v_position;
varying vec3 v_world_position;
varying vec3 v_normal;
varying vec2 v_uv;
varying vec4 v_color;

uniform vec3 u_camera_pos;

uniform vec4 u_color;
uniform sampler2D u_color_texture;
uniform sampler2D u_emissive_texture;
uniform sampler2D u_metallic_texture;
uniform sampler2D u_normal_texture;
uniform sampler2D u_occlusion_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

//from the light types
uniform int u_light_type;

uniform vec3 u_ambient_light;

uniform vec3 u_light_position;
uniform vec3 u_light_color;
uniform vec3 u_light_direction;


uniform float u_max_distance;

uniform float u_cone_angle_cos;
uniform float u_cone_exp;

//whether to use alpha and emissive or not. If used every iteration illumination is incorrect
uniform bool u_first_pass;
uniform bool u_use_normalmap;

uniform bool u_cast_shadows;
uniform sampler2D u_shadow_atlas;

uniform vec4 u_light_shadow_slot;
uniform mat4 u_light_viewprojection;
uniform float u_shadow_bias;

#define PI 3.141592

vec2 reproject_uv(vec2 uv, vec4 dimensions){
    return vec2(dimensions.x + (uv.x * dimensions.z), dimensions.y + (uv.y * dimensions.a));
}

float test_shadowmap(vec3 wp){
    //project our 3D position to the shadowmap
    vec4 proj_pos = u_light_viewprojection * vec4(wp,1.0);

    //from homogeneus space to clip space
    vec2 shadow_uv = proj_pos.xy / proj_pos.w;

    //from clip space to uv space
    shadow_uv = shadow_uv * 0.5 + vec2(0.5);

    //reproject because atlas
    shadow_uv = reproject_uv(shadow_uv, u_light_shadow_slot);

    //get point depth [-1 .. +1] in non-linear space
    float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;

    //normalize from [-1..+1] to [0..+1] still non-linear
    real_depth = real_depth * 0.5 + 0.5;

    //read depth from depth buffer in [0..+1] non-linear
    float shadow_depth = texture2D( u_shadow_atlas, shadow_uv).x;

    //compute final shadow factor by comparing
    float shadow_factor = 1.0;

    //we can compare them, even if they are not linear
    if( shadow_depth < real_depth )
    shadow_factor = 0.0;
    return shadow_factor;
}

float spot_factor(vec3 light_direction, vec3 L, float cos_limit, float cone_exp){
    float light_dot = -dot(light_direction, L);
    if (light_dot < cos_limit){
        return 0.0;
        }
    else{
        light_dot = (light_dot - cos_limit)/(1.0-cos_limit);
        return pow(light_dot, cone_exp);
    }
}

// the code from the slides
mat3 cotangent_frame(vec3 N, vec3 p, vec2 uv)
{
    // get edge vectors of the pixel triangle
    vec3 dp1 = dFdx( p );
    vec3 dp2 = dFdy( p );
    vec2 duv1 = dFdx( uv );
    vec2 duv2 = dFdy( uv );
    
    // solve the linear system
    vec3 dp2perp = cross( dp2, N );
    vec3 dp1perp = cross( N, dp1 );
    vec3 T = dp2perp * duv1.x + dp1perp * duv2.x;
    vec3 B = dp2perp * duv1.y + dp1perp * duv2.y;
 
    // construct a scale-invariant frame
    float invmax = inversesqrt( max( dot(T,T), dot(B,B) ) );
    return mat3( T * invmax, B * invmax, N );
}

// assume N, the interpolated vertex normal and
// WP the world position
//vec3 normal_pixel = texture2D( normalmap, uv ).xyz;
vec3 perturbNormal(vec3 N, vec3 WP, vec2 uv, vec3 normal_pixel)
{
    normal_pixel = normal_pixel * 255./127. - 128./127.;
    mat3 TBN = cotangent_frame(N, WP, uv);
    return normalize(TBN * normal_pixel);
}

// Normal Distribution Function using GGX Distribution
float D_GGX (	const in float NoH, 
const in float linearRoughness )
{
	float a2 = linearRoughness * linearRoughness;
	float f = (NoH * NoH) * (a2 - 1.0) + 1.0;
	return a2 / (PI * f * f);
}

// Fresnel term with colorized fresnel
vec3 F_Schlick( const in float VoH, 
const in vec3 f0)
{
	float f = pow(1.0 - VoH, 5.0);
	return f0 + (vec3(1.0) - f0) * f;
}

// Geometry Term: Geometry masking/shadowing due to microfacets
float GGX(float NdotV, float k){
	return NdotV / (NdotV * (1.0 - k) + k);
}
	
float G_Smith( float NdotV, float NdotL, float roughness)
{
	float k = pow(roughness + 1.0, 2.0) / 8.0;
	return GGX(NdotL, k) * GGX(NdotV, k);
}


//this is the cook torrance specular reflection model
vec3 specularBRDF( float roughness, vec3 f0, 
float NoH, float NoV, float NoL, float LoH )
{
float a = roughness * roughness;

// Normal Distribution Function
float D = D_GGX( NoH, a );

	// Fresnel Function
	vec3 F = F_Schlick( LoH, f0 );

	// Visibility Function (shadowing/masking)
	float G = G_Smith( NoV, NoL, roughness );
		
	// Norm factor
	vec3 spec = D * G * F;
	spec /= (4.0 * NoL * NoV + 1e-6);

	return spec;
}


void main()
{
    if (u_light_type == 0)
        discard;
        
    vec2 uv = v_uv;
    vec4 color = u_color;
    color *= texture2D( u_color_texture, uv );
    
    if(color.a < u_alpha_cutoff)
        discard;
        
    //use occlusion for ambient light
    vec3 light = u_ambient_light * texture2D (u_occlusion_texture, uv).xyz;
    
    //very important to normalize as they come
    //interpolated so normalization is lost
    vec3 N = vec3(0.0);
    
    if (u_use_normalmap)
        N = perturbNormal(v_normal, v_world_position, uv, texture2D( u_normal_texture, uv ).xyz);
    else
        N = normalize( v_normal );
    
    float att_factor = 1.0;
    //hol up





    vec3 L = u_light_direction;
    //compute att factor and L if light is not directional

    if (u_light_type != 3){
        L = u_light_position - v_world_position;

        float light_distance = length(L);
        L /= light_distance;
        
        att_factor =  u_max_distance - light_distance;
        att_factor = max(att_factor / u_max_distance, 0.0);
        att_factor = pow(att_factor, 2.0);
    }else{
        L = normalize(L);
    }



    float NdotL = clamp(dot(N, L), 0.0, 1.0);
    float spot_factor = 1.0;
    
    float shadow_factor = 1.0;
    if (u_light_type == 2)
    //spot factor if light is spot
        spot_factor = spot_factor(u_light_direction, L, u_cone_angle_cos, u_cone_exp);

    if(u_cast_shadows)
        shadow_factor = test_shadowmap(v_world_position);
    
        
    //store the amount of diffuse light
    light += u_light_color * clamp(NdotL * att_factor * spot_factor * shadow_factor, 0.0, 1.0);

    // if it is the first pass we use the color alpha. If not we set it to 0 to avoid adding anything that should be only added once
    float alpha = u_first_pass ? color.a : 0.0;

    vec3 emissive_value = u_first_pass ? texture2D (u_emissive_texture, uv).xyz : vec3(0.0);
    gl_FragColor = vec4(color.xyz * light + emissive_value, alpha);
}

\singlephong.fs

const int MAX_LIGHTS = 6;
varying vec3 v_position;
varying vec3 v_world_position;
varying vec3 v_normal;
varying vec2 v_uv;
varying vec4 v_color;

uniform vec3 u_camera_pos;

uniform vec4 u_color;
uniform sampler2D u_color_texture;
uniform sampler2D u_emissive_texture;
uniform sampler2D u_metallic_texture;
uniform sampler2D u_normal_texture;
uniform sampler2D u_occlusion_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

//from the light types
uniform int u_light_type[MAX_LIGHTS];

uniform vec3 u_ambient_light;

uniform vec3 u_light_position[MAX_LIGHTS];
uniform vec3 u_light_color[MAX_LIGHTS];
uniform vec3 u_light_direction[MAX_LIGHTS];


uniform float u_max_distance[MAX_LIGHTS];

uniform float u_cone_angle_cos[MAX_LIGHTS];
uniform float u_cone_exp[MAX_LIGHTS];

uniform int u_num_lights;
uniform bool u_use_normalmap;

uniform bool u_cast_shadows[MAX_LIGHTS];
uniform sampler2D u_shadow_atlas;
//THIS NEEDS TO BE NORMALIZED 0-1
uniform vec4 u_light_shadow_slot[MAX_LIGHTS];
uniform mat4 u_light_viewprojection[MAX_LIGHTS];
uniform float u_shadow_bias[MAX_LIGHTS];

#define PI 3.141592

vec2 reproject_uv(vec2 uv, vec4 dimensions){
    return vec2(dimensions.x + (uv.x * dimensions.z), dimensions.y + (uv.y * dimensions.a));
}

// needs vec4 light_shadow_info
float test_shadowmap(vec3 wp, int i){
    //project our 3D position to the shadowmap
    vec4 proj_pos = u_light_viewprojection[i] * vec4(wp,1.0);

    //from homogeneus space to clip space
    vec2 shadow_uv = proj_pos.xy / proj_pos.w;

    //from clip space to uv space
    shadow_uv = shadow_uv * 0.5 + vec2(0.5);

    //reproject because atlas
    shadow_uv = reproject_uv(shadow_uv, u_light_shadow_slot[i]);

    //get point depth [-1 .. +1] in non-linear space
    float real_depth = (proj_pos.z - u_shadow_bias[i]) / proj_pos.w;

    //normalize from [-1..+1] to [0..+1] still non-linear
    real_depth = real_depth * 0.5 + 0.5;

    //read depth from depth buffer in [0..+1] non-linear
    float shadow_depth = texture2D( u_shadow_atlas, shadow_uv).x;

    //compute final shadow factor by comparing
    float shadow_factor = 1.0;

    //we can compare them, even if they are not linear
    if( shadow_depth < real_depth )
    shadow_factor = 0.0;
    return shadow_factor;
}

float spot_factor(vec3 light_direction, vec3 L, float cos_limit, float cone_exp){
        float light_dot = -dot(light_direction, L);
        if (light_dot < cos_limit){
            return 0.0;
        }
        else{
            light_dot = (light_dot - cos_limit)/(1.0-cos_limit);
            return pow(light_dot, cone_exp);
        }
}

//the code from the slides
mat3 cotangent_frame(vec3 N, vec3 p, vec2 uv)
{
    // get edge vectors of the pixel triangle
    vec3 dp1 = dFdx( p );
    vec3 dp2 = dFdy( p );
    vec2 duv1 = dFdx( uv );
    vec2 duv2 = dFdy( uv );
    
    // solve the linear system
    vec3 dp2perp = cross( dp2, N );
    vec3 dp1perp = cross( N, dp1 );
    vec3 T = dp2perp * duv1.x + dp1perp * duv2.x;
    vec3 B = dp2perp * duv1.y + dp1perp * duv2.y;
 
    // construct a scale-invariant frame
    float invmax = inversesqrt( max( dot(T,T), dot(B,B) ) );
    return mat3( T * invmax, B * invmax, N );
}

// assume N, the interpolated vertex normal and
// WP the world position
//vec3 normal_pixel = texture2D( normalmap, uv ).xyz;
vec3 perturbNormal(vec3 N, vec3 WP, vec2 uv, vec3 normal_pixel)
{
    normal_pixel = normal_pixel * 255./127. - 128./127.;
    mat3 TBN = cotangent_frame(N, WP, uv);
    return normalize(TBN * normal_pixel);
}

// Normal Distribution Function using GGX Distribution
float D_GGX (	const in float NoH, 
const in float linearRoughness )
{
	float a2 = linearRoughness * linearRoughness;
	float f = (NoH * NoH) * (a2 - 1.0) + 1.0;
	return a2 / (PI * f * f);
}

// Fresnel term with colorized fresnel
vec3 F_Schlick( const in float VoH, 
const in vec3 f0)
{
	float f = pow(1.0 - VoH, 5.0);
	return f0 + (vec3(1.0) - f0) * f;
}

// Geometry Term: Geometry masking/shadowing due to microfacets
float GGX(float NdotV, float k){
	return NdotV / (NdotV * (1.0 - k) + k);
}
	
float G_Smith( float NdotV, float NdotL, float roughness)
{
	float k = pow(roughness + 1.0, 2.0) / 8.0;
	return GGX(NdotL, k) * GGX(NdotV, k);
}


//this is the cook torrance specular reflection model
vec3 specularBRDF( float roughness, vec3 f0, 
float NoH, float NoV, float NoL, float LoH )
{
float a = roughness * roughness;

// Normal Distribution Function
float D = D_GGX( NoH, a );

	// Fresnel Function
	vec3 F = F_Schlick( LoH, f0 );

	// Visibility Function (shadowing/masking)
	float G = G_Smith( NoV, NoL, roughness );
		
	// Norm factor
	vec3 spec = D * G * F;
	spec /= (4.0 * NoL * NoV + 1e-6);

	return spec;
}

void main()
{
    vec2 uv = v_uv;
    vec4 color = u_color;
    color *= texture2D( u_color_texture, uv );

    if(color.a < u_alpha_cutoff)
        discard;
        
    //occlusion for ambient light
    vec3 light = u_ambient_light * texture2D (u_occlusion_texture, uv).xyz;
    vec3 N = vec3(0.0);
    if(u_use_normalmap)
        N = perturbNormal(v_normal, v_world_position, v_uv, texture2D( u_normal_texture, uv ).xyz);
    else
        N = normalize( v_normal );
    
    float att_factor = 1.0;
    //each light computes NdotL according to their type
    for( int i = 0; i < MAX_LIGHTS; ++i )
    {
        if(i < u_num_lights)
        {
        // hol up
            vec3 L = u_light_direction[i];

            if(u_light_type[i] != 3){
                L = u_light_position[i] - v_world_position;

                float light_distance = length(L);
                L /= light_distance;
            
                att_factor =  u_max_distance[i] - light_distance;
                att_factor = max(att_factor / u_max_distance[i], 0.0);
                att_factor = pow(att_factor, 2.0);
            }else{
                L = normalize(L);
            }
            
            float NdotL = clamp(dot(N, L), 0.0, 1.0);
            float spot_factor = 1.0;
            
            float shadow_factor = 1.0;
            if (u_light_type[i] == 2)
                //spot factor if light is spot
                spot_factor = spot_factor(u_light_direction[i], L, u_cone_angle_cos[i], u_cone_exp[i]);
                
            if(u_cast_shadows[i])
                shadow_factor = test_shadowmap(v_world_position, i);
            
            
            //store the amount of diffuse light
            light += u_light_color[i] * clamp(NdotL * att_factor * spot_factor * shadow_factor, 0.0, 1.0);
        }
    }

    //alpha and emissive texture only used once in singlepass
    vec3 emissive_value = texture2D (u_emissive_texture, uv).xyz;
    gl_FragColor = vec4(color.xyz * light + emissive_value, color.a);
}

\quad.vs

attribute vec3 a_vertex;
attribute vec2 a_coord;
varying vec2 v_uv;

void main()
{	
	v_uv = a_coord;
	gl_Position = vec4( a_vertex, 1.0 );
}


\multi.fs

#version 330 core

varying vec3 v_position;
varying vec3 v_world_position;
varying vec3 v_normal;
varying vec2 v_uv;

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_texture, uv );

	if(color.a < u_alpha_cutoff)
		discard;

	vec3 N = normalize(v_normal);

	gl_FragData[0] = color;
	gl_FragData[1] = vec4(N,1.0);
}


\depth.fs

//version 330 core

uniform vec2 u_camera_nearfar;
uniform sampler2D u_texture; //depth map
varying vec2 v_uv;

void main()
{
	float n = u_camera_nearfar.x;
	float f = u_camera_nearfar.y;
	float z = texture2D(u_texture,v_uv).x;
	float color = n * (z + 1.0) / (f + n - z * (f - n));
	gl_FragColor = vec4(color);
}

\instanced.vs


attribute vec3 a_vertex;
attribute vec3 a_normal;
attribute vec2 a_coord;

attribute mat4 u_model;

uniform vec3 u_camera_pos;

uniform mat4 u_viewprojection;

//this will store the color for the pixel shader
varying vec3 v_position;
varying vec3 v_world_position;
varying vec3 v_normal;
varying vec2 v_uv;

void main()
{	
	//calcule the normal in camera space (the NormalMatrix is like ViewMatrix but without traslation)
	v_normal = (u_model * vec4( a_normal, 0.0) ).xyz;
	
	//calcule the vertex in object space
	v_position = a_vertex;
	v_world_position = (u_model * vec4( a_vertex, 1.0) ).xyz;
	
	//store the texture coordinates
	v_uv = a_coord;

	//calcule the position of the vertex using the matrices
	gl_Position = u_viewprojection * vec4( v_world_position, 1.0 );
}
